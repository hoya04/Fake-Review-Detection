{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e6e3c1a",
   "metadata": {},
   "source": [
    "# 1. 텍스트 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc297b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sinjeongho/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sinjeongho/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sinjeongho/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # 데이터프레임을 다루는 기본 데이터 분석 라이브러리\n",
    "import numpy as np # 수치 계산 및 배열 처리를 위한 라이브러리\n",
    "import re # 정규표현식(re) 라이브러리\n",
    "import nltk # 자연어처리용 통합 라이브러리\n",
    "import inflect # 숫자 → 문자 변환 등을 위한 텍스트 수 처리 라이브러리\n",
    "import contractions # 축약어 복원 (예: “don’t” → “do not”)\n",
    "\n",
    "from bs4 import BeautifulSoup # HTML 태그 제거 등에 사용하는 웹 파싱 도구\n",
    "from nltk import word_tokenize # 단어 토큰화 (문장을 단어로 나누는 작업) 도구\n",
    "from nltk.corpus import stopwords # 의미 없는 단어(불용어)를 불러오기 위한 모듈 \n",
    "from nltk.stem import WordNetLemmatizer # 단어의 원형(표제어)로 변환하는 데 사용\n",
    "from nltk import pos_tag # 단어에 품사 태깅을 위한 모듈 (단어가 명사인지, 동사인지, 부사인지 판단)\n",
    "from nltk.corpus import wordnet # WordNet 전용 품사 태그를 제공하는 모듈\n",
    "\n",
    "from tqdm import tqdm # 작업 진행 상태를 시각적으로 표시하는 라이브러리\n",
    "tqdm.pandas() # pandas에서 tqdm 진행률 바 사용 가능하게 확장\n",
    "\n",
    "nltk.download('stopwords') # 불용어 리스트 다운로드\n",
    "nltk.download('punkt') # 문장/단어 분리기용 데이터 다운로드\n",
    "nltk.download('wordnet') # 표제어 처리용 WordNet 리소스 다운로드\n",
    "\n",
    "stop_words = set(stopwords.words('english')) # 영어 불용어 목록 로드\n",
    "lemmatizer = WordNetLemmatizer() # 표제어 추출을 위한 lemmatizer 객체 생성\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aae4a1",
   "metadata": {},
   "source": [
    "텍스트 전처리 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd0ff92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'): return wordnet.ADJ # 형용사\n",
    "    elif tag.startswith('V'): return wordnet.VERB # 동사\n",
    "    elif tag.startswith('N'): return wordnet.NOUN # 명사\n",
    "    elif tag.startswith('R'): return wordnet.ADV # 부사\n",
    "    else: return wordnet.NOUN # 기본값은 명사로 설정\n",
    "\n",
    "def clean_txt(txt): \n",
    "    if txt is not None: # 입력값이 None이 아닌 경우에만 처리\n",
    "        txt = str(txt) # 문자열로 강제 변환\n",
    "        txt = BeautifulSoup(txt, \"html.parser\").get_text() # HTML 태그 제거\n",
    "        txt = contractions.fix(txt) # 축약어 복원 (e.g., \"don't\" → \"do not\")\n",
    "        txt = re.sub('[^a-zA-Z]', ' ', txt) # 알파벳 제외한 문자 모두 공백으로 대체\n",
    "        txt = txt.lower() # 모두 소문자로 변환\n",
    "        txt = word_tokenize(txt) # 단어 단위로 토큰화\n",
    "        txt = [word for word in txt if word not in stop_words] # 불용어 제거\n",
    "        txt = [i for i in txt if len(i) > 2] # 길이가 2 이하인 단어 제거 (예: 'a', 'is' 등)\n",
    "        txt = [lemmatizer.lemmatize(w, get_wordnet_pos(t)) for w, t in pos_tag(txt)] # 표제어 추출 (품사 태깅 포함)\n",
    "        txt = ' '.join(txt) # 다시 문자열로 결합 (공백 구분)\n",
    "        return txt if txt else None # 결과가 빈 문자열일 경우 None 반환\n",
    "    return None # 입력값이 None인 경우 None 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba8d64ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(452947, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review_res</th>\n",
       "      <th>review_res_url</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_date</th>\n",
       "      <th>reviewer_url</th>\n",
       "      <th>review_text</th>\n",
       "      <th>photo</th>\n",
       "      <th>location</th>\n",
       "      <th>reputation</th>\n",
       "      <th>...</th>\n",
       "      <th>emotion</th>\n",
       "      <th>Social</th>\n",
       "      <th>Perception</th>\n",
       "      <th>motion</th>\n",
       "      <th>fake</th>\n",
       "      <th>experience</th>\n",
       "      <th>Psychological Distancing</th>\n",
       "      <th>review_extremity</th>\n",
       "      <th>style</th>\n",
       "      <th>preprocessing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Benemon</td>\n",
       "      <td>/biz/benemon-new-york?osq=Restaurants</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2/16/2023</td>\n",
       "      <td>/user_details?userid=pkppXY0hRJbXt6ELI_9X9Q</td>\n",
       "      <td>Good Japanese street food.Great choice of sake...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>6.67</td>\n",
       "      <td>6.67</td>\n",
       "      <td>6.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>['good', 'japanese', 'street', 'food.great', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Burger &amp; Lobster - Flatiron NYC</td>\n",
       "      <td>/biz/burger-and-lobster-flatiron-nyc-new-york?...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1/29/2022</td>\n",
       "      <td>/user_details?userid=pkppXY0hRJbXt6ELI_9X9Q</td>\n",
       "      <td>Great service and food was awesome. Cool atmos...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>6.67</td>\n",
       "      <td>13.33</td>\n",
       "      <td>26.67</td>\n",
       "      <td>13.33</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>13.33</td>\n",
       "      <td>['great', 'service', 'food', 'awesome', 'cool'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Benemon</td>\n",
       "      <td>/biz/benemon-new-york?osq=Restaurants</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1/25/2023</td>\n",
       "      <td>/user_details?userid=jH4neSuhaxEoPGBmpNNK5Q</td>\n",
       "      <td>I was really missing the amazing Izakayas in J...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>268</td>\n",
       "      <td>...</td>\n",
       "      <td>5.26</td>\n",
       "      <td>4.68</td>\n",
       "      <td>11.11</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>['really', 'miss', 'amaze', 'izakayas', 'japan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Saigon Shack</td>\n",
       "      <td>/biz/saigon-shack-new-york?osq=Restaurants</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9/13/2021</td>\n",
       "      <td>/user_details?userid=jH4neSuhaxEoPGBmpNNK5Q</td>\n",
       "      <td>Cash only but there is an ATM right outside. E...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>5.31</td>\n",
       "      <td>12.39</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.42</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.19</td>\n",
       "      <td>['cash', 'right', 'outside', 'even', 'monday',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Thai Diner</td>\n",
       "      <td>/biz/thai-diner-new-york?osq=Restaurants</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12/20/2022</td>\n",
       "      <td>/user_details?userid=jH4neSuhaxEoPGBmpNNK5Q</td>\n",
       "      <td>From the same team that brought us Uncle Boons...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>268</td>\n",
       "      <td>...</td>\n",
       "      <td>1.73</td>\n",
       "      <td>7.79</td>\n",
       "      <td>7.36</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.73</td>\n",
       "      <td>['team', 'bring', 'uncle', 'boons', 'favorite'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       review_res  \\\n",
       "0           0                          Benemon   \n",
       "1           1  Burger & Lobster - Flatiron NYC   \n",
       "2           2                          Benemon   \n",
       "3           3                     Saigon Shack   \n",
       "4           4                       Thai Diner   \n",
       "\n",
       "                                      review_res_url  rating review_date  \\\n",
       "0              /biz/benemon-new-york?osq=Restaurants     5.0   2/16/2023   \n",
       "1  /biz/burger-and-lobster-flatiron-nyc-new-york?...     5.0   1/29/2022   \n",
       "2              /biz/benemon-new-york?osq=Restaurants     5.0   1/25/2023   \n",
       "3         /biz/saigon-shack-new-york?osq=Restaurants     5.0   9/13/2021   \n",
       "4           /biz/thai-diner-new-york?osq=Restaurants     5.0  12/20/2022   \n",
       "\n",
       "                                  reviewer_url  \\\n",
       "0  /user_details?userid=pkppXY0hRJbXt6ELI_9X9Q   \n",
       "1  /user_details?userid=pkppXY0hRJbXt6ELI_9X9Q   \n",
       "2  /user_details?userid=jH4neSuhaxEoPGBmpNNK5Q   \n",
       "3  /user_details?userid=jH4neSuhaxEoPGBmpNNK5Q   \n",
       "4  /user_details?userid=jH4neSuhaxEoPGBmpNNK5Q   \n",
       "\n",
       "                                         review_text  photo  location  \\\n",
       "0  Good Japanese street food.Great choice of sake...      3         0   \n",
       "1  Great service and food was awesome. Cool atmos...      6         0   \n",
       "2  I was really missing the amazing Izakayas in J...      3         0   \n",
       "3  Cash only but there is an ATM right outside. E...      2         0   \n",
       "4  From the same team that brought us Uncle Boons...      1         0   \n",
       "\n",
       "   reputation  ...  emotion  Social  Perception  motion  fake  experience  \\\n",
       "0           6  ...     6.67    6.67        6.67    0.00     0        11.0   \n",
       "1           6  ...     6.67   13.33       26.67   13.33     0        11.0   \n",
       "2         268  ...     5.26    4.68       11.11    2.92     0        50.0   \n",
       "3         268  ...     0.88    5.31       12.39    2.65     0        50.0   \n",
       "4         268  ...     1.73    7.79        7.36    0.87     0        50.0   \n",
       "\n",
       "   Psychological Distancing  review_extremity  style  \\\n",
       "0                      0.00              25.0   0.00   \n",
       "1                      0.00              25.0  13.33   \n",
       "2                      2.92              25.0   1.17   \n",
       "3                      4.42              25.0   6.19   \n",
       "4                      3.89              25.0   1.73   \n",
       "\n",
       "                                       preprocessing  \n",
       "0  ['good', 'japanese', 'street', 'food.great', '...  \n",
       "1  ['great', 'service', 'food', 'awesome', 'cool'...  \n",
       "2  ['really', 'miss', 'amaze', 'izakayas', 'japan...  \n",
       "3  ['cash', 'right', 'outside', 'even', 'monday',...  \n",
       "4  ['team', 'bring', 'uncle', 'boons', 'favorite'...  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.read_pickle('final_use.pkl')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bb3b51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good Japanese street food.Great choice of sake...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great service and food was awesome. Cool atmos...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I was really missing the amazing Izakayas in J...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cash only but there is an ATM right outside. E...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From the same team that brought us Uncle Boons...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  fake\n",
       "0  Good Japanese street food.Great choice of sake...     0\n",
       "1  Great service and food was awesome. Cool atmos...     0\n",
       "2  I was really missing the amazing Izakayas in J...     0\n",
       "3  Cash only but there is an ATM right outside. E...     0\n",
       "4  From the same team that brought us Uncle Boons...     0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(['Unnamed: 0', 'review_res', 'review_res_url', 'rating', 'review_date',\n",
    "       'reviewer_url',  'photo', 'location', 'reputation',\n",
    "       'reviewer_photo', 'depth', 'text_structure', 'Cognition', 'Affect',\n",
    "       'emotion', 'Social', 'Perception', 'motion',  'experience',\n",
    "       'Psychological Distancing', 'review_extremity', 'style',\n",
    "       'preprocessing'],axis=1,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "832aa55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fake\n",
       "0    409983\n",
       "1     42964\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('raw_data.pkl')\n",
    "df['fake'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3123df2f",
   "metadata": {},
   "source": [
    "## PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75294f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(tag): #표제어 추출출`   `\n",
    "    if tag.startswith('J'): return wordnet.ADJ # 형용사\n",
    "    elif tag.startswith('V'): return wordnet.VERB # 동사\n",
    "    elif tag.startswith('N'): return wordnet.NOUN # 명사\n",
    "    elif tag.startswith('R'): return wordnet.ADV # 부사\n",
    "    else: return wordnet.NOUN # 기본값은 명사로 설정\n",
    "\n",
    "def clean_txt(txt): \n",
    "    if txt is not None: # 입력값이 None이 아닌 경우에만 처리\n",
    "        txt = str(txt)\n",
    "        if not re.search('[a-zA-Z]', txt):  # 영어가 없으면 제거\n",
    "            return None\n",
    "        txt = BeautifulSoup(txt, \"html.parser\").get_text() # HTML 태그 제거\n",
    "        txt = contractions.fix(txt) # 축약어 복원 (e.g., \"don't\" → \"do not\")\n",
    "        txt = re.sub('[^a-zA-Z]', ' ', txt) # 알파벳 제외한 문자 모두 공백으로 대체\n",
    "        \n",
    "        txt = txt.lower() # 모두 소문자로 변환\n",
    "        txt = word_tokenize(txt) # 단어 단위로 토큰화\n",
    "        txt = [word for word in txt if word not in stop_words] # 불용어 제거\n",
    "        txt = [i for i in txt if len(i) > 2] # 길이가 2 이하인 단어 제거 (예: 'a', 'is' 등)\n",
    "        txt = [lemmatizer.lemmatize(w, get_wordnet_pos(t)) for w, t in pos_tag(txt)] # 표제어 추출 (품사 태깅 포함)\n",
    "        txt = ' '.join(txt) # 다시 문자열로 결합 (공백 구분)\n",
    "        return txt if txt else None # 결과가 빈 문자열일 경우 None 반환\n",
    "    return None # 입력값이 None인 경우 None 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "427bc51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 452947/452947 [08:35<00:00, 878.24it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(452947, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>fake</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good Japanese street food.Great choice of sake...</td>\n",
       "      <td>0</td>\n",
       "      <td>good japanese street food great choice sake qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great service and food was awesome. Cool atmos...</td>\n",
       "      <td>0</td>\n",
       "      <td>great service food awesome cool atmosphere go ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I was really missing the amazing Izakayas in J...</td>\n",
       "      <td>0</td>\n",
       "      <td>really miss amaze izakayas japan decide stop t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cash only but there is an ATM right outside. E...</td>\n",
       "      <td>0</td>\n",
       "      <td>cash atm right outside even monday night degre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From the same team that brought us Uncle Boons...</td>\n",
       "      <td>0</td>\n",
       "      <td>team bring uncle boon old favorite michelin st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  fake  \\\n",
       "0  Good Japanese street food.Great choice of sake...     0   \n",
       "1  Great service and food was awesome. Cool atmos...     0   \n",
       "2  I was really missing the amazing Izakayas in J...     0   \n",
       "3  Cash only but there is an ATM right outside. E...     0   \n",
       "4  From the same team that brought us Uncle Boons...     0   \n",
       "\n",
       "                                          clean_text  \n",
       "0  good japanese street food great choice sake qu...  \n",
       "1  great service food awesome cool atmosphere go ...  \n",
       "2  really miss amaze izakayas japan decide stop t...  \n",
       "3  cash atm right outside even monday night degre...  \n",
       "4  team bring uncle boon old favorite michelin st...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'] = df['review_text'].progress_apply(clean_txt)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3364892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_text    0\n",
       "fake           0\n",
       "clean_text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['clean_text'].notnull()]\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "377530fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fake\n",
       "0    409977\n",
       "1     42880\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fake'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38d2c157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of 0         good japanese street food great choice sake qu...\n",
       "1         great service food awesome cool atmosphere go ...\n",
       "2         really miss amaze izakayas japan decide stop t...\n",
       "3         cash atm right outside even monday night degre...\n",
       "4         team bring uncle boon old favorite michelin st...\n",
       "                                ...                        \n",
       "452942    best italian ever good food nice staff well lo...\n",
       "452943                             cute place love food yum\n",
       "452944    one bad meal recent memory food mediocre poorl...\n",
       "452945    often cry amaze food laugh great service din p...\n",
       "452946    food amaze arancini clam toast chitarra hot ch...\n",
       "Name: clean_text, Length: 452857, dtype: object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'].head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4965157e",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "199e1b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_false = df[df['fake'] == 1].sample(42880)  # 긍정 리뷰 샘플링\n",
    "df_true = df[df['fake'] == 0].sample(42880)  # 부정 리뷰 샘플링\n",
    "# 데이터 결합\n",
    "df_concat = pd.concat([df_false, df_true])\n",
    "df_concat.reset_index(drop=True, inplace=True)  # 인덱스 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef13cadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_concat, test_size=0.2, random_state=42, stratify=df_concat[\"fake\"])\n",
    "\n",
    "# 훈련 데이터 리뷰 텍스트와 라벨 추출\n",
    "x_train = df_train['clean_text']\n",
    "y_train = np.array(df_train['fake'])\n",
    "\n",
    "# 테스트 데이터 리뷰 텍스트와 라벨 추출\n",
    "x_test = df_test['clean_text']\n",
    "y_test = np.array(df_test['fake'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a836ff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_pickle('df_train.pkl')\n",
    "df_test.to_pickle('df_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fd8a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
