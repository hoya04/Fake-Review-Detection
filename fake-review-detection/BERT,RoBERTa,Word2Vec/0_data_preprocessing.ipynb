{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f42ad5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm  # 진행률 표시용\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c81e8b",
   "metadata": {},
   "source": [
    "## 1. 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1bcb60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_fake = pd.read_csv(\"NY_fake.csv\")\n",
    "ny_fake = ny_fake[[\"review_text\", \"fake\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7c532c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12419 entries, 0 to 12418\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   review_text  12419 non-null  object\n",
      " 1   fake         12419 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 194.2+ KB\n"
     ]
    }
   ],
   "source": [
    "ny_fake.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f244539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_true = pd.read_csv(\"NY_true.csv\")\n",
    "ny_true = ny_true[[\"review_text\", \"fake\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e80d0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 110433 entries, 0 to 110432\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   review_text  110433 non-null  object\n",
      " 1   fake         110433 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "ny_true.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e21e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "lv_fake = pd.read_csv(\"LV_fake.csv\")\n",
    "lv_fake = lv_fake[[\"review_text\", \"fake\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "992f3493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30545 entries, 0 to 30544\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   review_text  30545 non-null  object\n",
      " 1   fake         30545 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 477.4+ KB\n"
     ]
    }
   ],
   "source": [
    "lv_fake.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe1aea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "lv_true = pd.read_csv(\"LV_true.csv\")\n",
    "lv_true = lv_true[[\"review_text\", \"fake\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9467fa6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 299550 entries, 0 to 299549\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   review_text  299550 non-null  object\n",
      " 1   fake         299550 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "lv_true.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f15c2d",
   "metadata": {},
   "source": [
    "## 2. 데이터 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33a8758b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(452947, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ordered delivery and they canceled my order wi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shrimp Anago tendon was nothing special. No eg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great restaurant to dine at. I highly recommen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Great place for Asian fusions. Love their food...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bensimon in the east village serves tapas, don...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  fake\n",
       "0  Ordered delivery and they canceled my order wi...     1\n",
       "1  Shrimp Anago tendon was nothing special. No eg...     1\n",
       "2  Great restaurant to dine at. I highly recommen...     1\n",
       "3  Great place for Asian fusions. Love their food...     1\n",
       "4  Bensimon in the east village serves tapas, don...     1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([ny_fake, ny_true, lv_fake, lv_true]).reset_index(drop=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35873203",
   "metadata": {},
   "source": [
    "## 3. 기본 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35765377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def basic_clean(text):\n",
    "    # 1. 앞뒤 공백 제거\n",
    "    text = text.strip()\n",
    "    \n",
    "    # 2. HTML 태그 제거\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # 3. 영어가 아닌 단어 제거 (숫자, 한글, 특수문자 등 제거)\n",
    "    text = re.sub(r'\\b[^a-zA-Z]+\\b', ' ', text)\n",
    "    \n",
    "    # 4. 여러 공백 → 하나의 공백\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62c29162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 452947/452947 [00:22<00:00, 20285.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# 전처리 함수 적용\n",
    "df['cleaned_text'] = df['review_text'].progress_apply(basic_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2005c25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 수 기준으로 필터링 (5개 이하 제거)\n",
    "df = df[df['cleaned_text'].str.split().str.len() > 5].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a1ddbef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fake\n",
       "0    409917\n",
       "1     41488\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"fake\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fc5cd6",
   "metadata": {},
   "source": [
    "## 4. 데이터 샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0891805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 0에서 40,000개 추출\n",
    "df_0 = df[df['fake'] == 0].sample(n=40000, random_state=42)\n",
    "\n",
    "# 클래스 1에서 40,000개 추출\n",
    "df_1 = df[df['fake'] == 1].sample(n=40000, random_state=42)\n",
    "\n",
    "# 결합 및 인덱스 초기화\n",
    "df_balanced = pd.concat([df_0, df_1]).sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64f51d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fake\n",
       "1    40000\n",
       "0    40000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced[\"fake\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ba40c1",
   "metadata": {},
   "source": [
    "## 5. 임베딩 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1e4cc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: cuda\n",
      "[INFO] Loading BERT model and tokenizer...\n",
      "[INFO] Loading RoBERTa model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 디바이스 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"[INFO] Using device: {device}\")\n",
    "\n",
    "# 모델 및 토크나이저 로드\n",
    "print(\"[INFO] Loading BERT model and tokenizer...\")\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = AutoModel.from_pretrained('bert-base-uncased').to(device)\n",
    "\n",
    "print(\"[INFO] Loading RoBERTa model and tokenizer...\")\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "roberta_model = AutoModel.from_pretrained('roberta-base').to(device)\n",
    "\n",
    "# 배치 처리 기반 CLS 추출 함수\n",
    "def extract_cls_batch(texts, tokenizer, model, batch_size=16):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    dataloader = DataLoader(texts, batch_size=batch_size)\n",
    "\n",
    "    print(f\"[INFO] Starting CLS embedding extraction (batch_size={batch_size})...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(dataloader, desc=\"Extracting [CLS] tokens\")):\n",
    "            encodings = tokenizer(batch, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "            encodings = {k: v.to(device) for k, v in encodings.items()}\n",
    "            outputs = model(**encodings)\n",
    "            cls_batch = outputs.last_hidden_state[:, 0, :].cpu().tolist()\n",
    "            embeddings.extend(cls_batch)\n",
    "\n",
    "    print(\"[INFO] Embedding extraction complete.\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b8dc0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting CLS embedding extraction (batch_size=32)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting [CLS] tokens: 100%|██████████| 2500/2500 [01:07<00:00, 37.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Embedding extraction complete.\n",
      "[INFO] Starting CLS embedding extraction (batch_size=32)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting [CLS] tokens: 100%|██████████| 2500/2500 [01:04<00:00, 38.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Embedding extraction complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# [CLS] 임베딩 추출 및 저장\n",
    "df_balanced['bert_cls'] = extract_cls_batch(df_balanced['cleaned_text'], bert_tokenizer, bert_model, batch_size=32)\n",
    "df_balanced['roberta_cls'] = extract_cls_batch(df_balanced['cleaned_text'], roberta_tokenizer, roberta_model, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36851d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860c9c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.to_json(\"emb_cls.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ae50e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.read_json(\"emb_cls.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4fe37a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import contractions\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "import collections\n",
    "import collections.abc\n",
    "collections.Callable = collections.abc.Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d5b4071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting contractions\n",
      "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting textsearch>=0.0.21 (from contractions)\n",
      "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
      "  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
      "  Downloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (13 kB)\n",
      "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
      "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "343918db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nltk\n",
      "Successfully installed nltk-3.9.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe2d61a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 정의 전처리 함수\n",
    "def preprocess_text(text):\n",
    "    # 1. HTML 태그 제거\n",
    "    text_no_html = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    \n",
    "    # 2. 축약어 확장\n",
    "    expanded_text = contractions.fix(text_no_html)\n",
    "    \n",
    "    # 3. 특수 문자 제거\n",
    "    text_no_specials = re.sub(r'[^a-zA-Z]', ' ', expanded_text)\n",
    "    \n",
    "    # 4. 공백 정리\n",
    "    text_clean = re.sub(r'\\s+', ' ', text_no_specials).strip()\n",
    "    \n",
    "    # 5. 소문자 변환\n",
    "    text_lower = text_clean.lower()\n",
    "    \n",
    "    # 6. 토큰화 + 불용어 제거\n",
    "    tokens = word_tokenize(text_lower)\n",
    "    filtered_tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "\n",
    "    # === 6.5. 단어 길이 2 초과인 단어가 하나라도 없으면 제거 ===\n",
    "    if not any(len(word) > 2 for word in filtered_tokens):\n",
    "        return ''  # 제거 대상이므로 빈 문자열 반환\n",
    "    \n",
    "    # 7. 어간 추출\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
    "    \n",
    "    # 8. 공백으로 연결된 문자열로 반환\n",
    "    return ' '.join(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78ecd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# nltk 리소스 다운로드 (최초 실행 시 필요)\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e34b727b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>fake</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>bert_cls</th>\n",
       "      <th>roberta_cls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Awesome place to eat! Great atmosphere and fri...</td>\n",
       "      <td>1</td>\n",
       "      <td>Awesome place to eat Great atmosphere and frie...</td>\n",
       "      <td>[0.0792026445, -0.0128625417, 0.3162086904, 0....</td>\n",
       "      <td>[-0.0814717263, 0.0890230536, -0.0438717902, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great lunch date place! Food is amazing, not a...</td>\n",
       "      <td>1</td>\n",
       "      <td>Great lunch date place Food is amazing not a l...</td>\n",
       "      <td>[-0.0047885552, 0.108762987, 0.0148257306, -0....</td>\n",
       "      <td>[-0.05344918, 0.0875567347, -0.0044471626, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Best takeout Thai in the area and at a good pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>Best takeout Thai in the area and at a good pr...</td>\n",
       "      <td>[-0.1299686283, 0.1433178782, -0.0055814832, -...</td>\n",
       "      <td>[-0.030115934100000002, 0.0927834213, -0.01960...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we been here few times for birthdays and coupl...</td>\n",
       "      <td>1</td>\n",
       "      <td>we been here few times for birthdays and coupl...</td>\n",
       "      <td>[-0.0104819108, -0.207980454, 0.4680296183, -0...</td>\n",
       "      <td>[-0.0079873865, 0.019187642300000002, -0.02611...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Excellent food and service. Yummy Delicious!!!...</td>\n",
       "      <td>1</td>\n",
       "      <td>Excellent food and service Yummy Delicious Flo...</td>\n",
       "      <td>[-0.3778436184, -0.2384559363, -0.0925718844, ...</td>\n",
       "      <td>[-0.0456091613, 0.0996065363, -0.0168792922, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>Huge portions and decent taste. Wait time was ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Huge portions and decent taste Wait time was t...</td>\n",
       "      <td>[-0.4036887288, -0.34380817410000003, -0.05337...</td>\n",
       "      <td>[-0.0847916529, 0.0360725187, -0.0341092423, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>The smell pulls you in and the drinks are fant...</td>\n",
       "      <td>1</td>\n",
       "      <td>The smell pulls you in and the drinks are fant...</td>\n",
       "      <td>[-0.063299641, 0.1593655795, 0.1619270891, -0....</td>\n",
       "      <td>[-0.0443048216, 0.0366968066, -0.0658430830000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>One of the best Halal thai restaurants in NYC ...</td>\n",
       "      <td>1</td>\n",
       "      <td>One of the best Halal thai restaurants in NYC ...</td>\n",
       "      <td>[-0.02582689, -0.111468941, -0.109392680200000...</td>\n",
       "      <td>[-0.0276376922, 0.0901447907, -0.0091079036, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>I've been here a handful of times and each tim...</td>\n",
       "      <td>0</td>\n",
       "      <td>I ve been here a handful of times and each tim...</td>\n",
       "      <td>[-0.0458812565, -0.36073127390000004, 0.279482...</td>\n",
       "      <td>[-0.0723976791, 0.0933143795, -0.0459695086, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>How I wish one didn't have to walk through the...</td>\n",
       "      <td>0</td>\n",
       "      <td>How I wish one didn t have to walk through the...</td>\n",
       "      <td>[-0.0859115422, -0.0107760858, 0.5014580488, -...</td>\n",
       "      <td>[-0.0507114828, 0.0172716994, -0.0767837539, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             review_text  fake  \\\n",
       "0      Awesome place to eat! Great atmosphere and fri...     1   \n",
       "1      Great lunch date place! Food is amazing, not a...     1   \n",
       "2      Best takeout Thai in the area and at a good pr...     1   \n",
       "3      we been here few times for birthdays and coupl...     1   \n",
       "4      Excellent food and service. Yummy Delicious!!!...     1   \n",
       "...                                                  ...   ...   \n",
       "79995  Huge portions and decent taste. Wait time was ...     0   \n",
       "79996  The smell pulls you in and the drinks are fant...     1   \n",
       "79997  One of the best Halal thai restaurants in NYC ...     1   \n",
       "79998  I've been here a handful of times and each tim...     0   \n",
       "79999  How I wish one didn't have to walk through the...     0   \n",
       "\n",
       "                                            cleaned_text  \\\n",
       "0      Awesome place to eat Great atmosphere and frie...   \n",
       "1      Great lunch date place Food is amazing not a l...   \n",
       "2      Best takeout Thai in the area and at a good pr...   \n",
       "3      we been here few times for birthdays and coupl...   \n",
       "4      Excellent food and service Yummy Delicious Flo...   \n",
       "...                                                  ...   \n",
       "79995  Huge portions and decent taste Wait time was t...   \n",
       "79996  The smell pulls you in and the drinks are fant...   \n",
       "79997  One of the best Halal thai restaurants in NYC ...   \n",
       "79998  I ve been here a handful of times and each tim...   \n",
       "79999  How I wish one didn t have to walk through the...   \n",
       "\n",
       "                                                bert_cls  \\\n",
       "0      [0.0792026445, -0.0128625417, 0.3162086904, 0....   \n",
       "1      [-0.0047885552, 0.108762987, 0.0148257306, -0....   \n",
       "2      [-0.1299686283, 0.1433178782, -0.0055814832, -...   \n",
       "3      [-0.0104819108, -0.207980454, 0.4680296183, -0...   \n",
       "4      [-0.3778436184, -0.2384559363, -0.0925718844, ...   \n",
       "...                                                  ...   \n",
       "79995  [-0.4036887288, -0.34380817410000003, -0.05337...   \n",
       "79996  [-0.063299641, 0.1593655795, 0.1619270891, -0....   \n",
       "79997  [-0.02582689, -0.111468941, -0.109392680200000...   \n",
       "79998  [-0.0458812565, -0.36073127390000004, 0.279482...   \n",
       "79999  [-0.0859115422, -0.0107760858, 0.5014580488, -...   \n",
       "\n",
       "                                             roberta_cls  \n",
       "0      [-0.0814717263, 0.0890230536, -0.0438717902, -...  \n",
       "1      [-0.05344918, 0.0875567347, -0.0044471626, -0....  \n",
       "2      [-0.030115934100000002, 0.0927834213, -0.01960...  \n",
       "3      [-0.0079873865, 0.019187642300000002, -0.02611...  \n",
       "4      [-0.0456091613, 0.0996065363, -0.0168792922, -...  \n",
       "...                                                  ...  \n",
       "79995  [-0.0847916529, 0.0360725187, -0.0341092423, -...  \n",
       "79996  [-0.0443048216, 0.0366968066, -0.0658430830000...  \n",
       "79997  [-0.0276376922, 0.0901447907, -0.0091079036, -...  \n",
       "79998  [-0.0723976791, 0.0933143795, -0.0459695086, -...  \n",
       "79999  [-0.0507114828, 0.0172716994, -0.0767837539, -...  \n",
       "\n",
       "[80000 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f36e4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수 적용\n",
    "df_clean['cleaned_text'] = df_clean['review_text'].progress_apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c9e6f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this product is amazing loved it</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>worst experience ever do not buy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>excellent quality and fast shipping</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fake item very disappointed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not bad could be better</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>absolutely terrible would not recommend</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              cleaned_text  fake\n",
       "0         this product is amazing loved it     0\n",
       "1         worst experience ever do not buy     1\n",
       "2      excellent quality and fast shipping     0\n",
       "3              fake item very disappointed     1\n",
       "4                  not bad could be better     0\n",
       "5  absolutely terrible would not recommend     1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
