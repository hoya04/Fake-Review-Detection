{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    df = pd.read_json(path)\n",
    "    bert = np.array(df['bert_cls'].tolist())\n",
    "    roberta = np.array(df['roberta_cls'].tolist())\n",
    "    y = df['fake'].values\n",
    "    return bert, roberta, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    bert_input = layers.Input(shape=(768,))\n",
    "    roberta_input = layers.Input(shape=(768,))\n",
    "\n",
    "    # BERT branch\n",
    "    bert_branch = layers.Dense(256, activation='relu')(bert_input)\n",
    "    bert_branch = layers.Dropout(0.3)(bert_branch)\n",
    "    bert_branch = layers.Dense(128, activation='relu')(bert_branch)\n",
    "\n",
    "    # RoBERTa branch\n",
    "    roberta_branch = layers.Dense(256, activation='relu')(roberta_input)\n",
    "    roberta_branch = layers.Dropout(0.3)(roberta_branch)\n",
    "    roberta_branch = layers.Dense(128, activation='relu')(roberta_branch)\n",
    "\n",
    "    # Concatenate and output\n",
    "    combined = layers.Concatenate()([bert_branch, roberta_branch])\n",
    "    combined = layers.Dropout(0.3)(combined)\n",
    "    output = layers.Dense(1, activation='sigmoid')(combined)\n",
    "\n",
    "    model = models.Model(inputs=[bert_input, roberta_input], outputs=output)\n",
    "    model.compile(optimizer=optimizers.Adam(1e-4),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(bert, roberta, y):\n",
    "    X_train_bert, X_val_bert, y_train, y_val = train_test_split(\n",
    "        bert, y, test_size=0.2, stratify=y, random_state=42)\n",
    "    X_train_roberta, X_val_roberta, _, _ = train_test_split(\n",
    "        roberta, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "    model = build_model()\n",
    "\n",
    "    early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        [X_train_bert, X_train_roberta], y_train,\n",
    "        validation_data=([X_val_bert, X_val_roberta], y_val),\n",
    "        epochs=100,\n",
    "        batch_size=64,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "\n",
    "    y_pred_prob = model.predict([X_val_bert, X_val_roberta])\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    print(f\"Accuracy : {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall   : {rec:.4f}\")\n",
    "    print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6717 - loss: 0.6008 - val_accuracy: 0.7198 - val_loss: 0.5437\n",
      "Epoch 2/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7183 - loss: 0.5502 - val_accuracy: 0.7240 - val_loss: 0.5352\n",
      "Epoch 3/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7229 - loss: 0.5408 - val_accuracy: 0.7271 - val_loss: 0.5314\n",
      "Epoch 4/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7261 - loss: 0.5344 - val_accuracy: 0.7296 - val_loss: 0.5281\n",
      "Epoch 5/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7290 - loss: 0.5318 - val_accuracy: 0.7310 - val_loss: 0.5255\n",
      "Epoch 6/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7366 - loss: 0.5270 - val_accuracy: 0.7328 - val_loss: 0.5238\n",
      "Epoch 7/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7365 - loss: 0.5232 - val_accuracy: 0.7352 - val_loss: 0.5223\n",
      "Epoch 8/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7384 - loss: 0.5203 - val_accuracy: 0.7339 - val_loss: 0.5222\n",
      "Epoch 9/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7396 - loss: 0.5185 - val_accuracy: 0.7356 - val_loss: 0.5213\n",
      "Epoch 10/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7414 - loss: 0.5152 - val_accuracy: 0.7349 - val_loss: 0.5204\n",
      "Epoch 11/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7435 - loss: 0.5125 - val_accuracy: 0.7368 - val_loss: 0.5213\n",
      "Epoch 12/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7445 - loss: 0.5109 - val_accuracy: 0.7371 - val_loss: 0.5193\n",
      "Epoch 13/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7466 - loss: 0.5066 - val_accuracy: 0.7361 - val_loss: 0.5204\n",
      "Epoch 14/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7485 - loss: 0.5043 - val_accuracy: 0.7368 - val_loss: 0.5196\n",
      "Epoch 15/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7519 - loss: 0.5008 - val_accuracy: 0.7377 - val_loss: 0.5209\n",
      "Epoch 16/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7516 - loss: 0.4982 - val_accuracy: 0.7331 - val_loss: 0.5236\n",
      "Epoch 17/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7551 - loss: 0.4953 - val_accuracy: 0.7347 - val_loss: 0.5220\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step\n",
      "Accuracy : 0.7371\n",
      "Precision: 0.7285\n",
      "Recall   : 0.7559\n",
      "F1 Score : 0.7419\n"
     ]
    }
   ],
   "source": [
    "# 실행\n",
    "bert, roberta, y = load_data(\"emb_cls.json\")\n",
    "model = train_model(bert, roberta, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Multiply\n",
    "def build_model_multiply():\n",
    "    bert_input = layers.Input(shape=(768,))\n",
    "    roberta_input = layers.Input(shape=(768,))\n",
    "\n",
    "    # BERT branch\n",
    "    bert_branch = layers.Dense(256, activation='relu')(bert_input)\n",
    "    bert_branch = layers.Dropout(0.3)(bert_branch)\n",
    "    bert_branch = layers.Dense(128, activation='relu')(bert_branch)\n",
    "\n",
    "    # RoBERTa branch\n",
    "    roberta_branch = layers.Dense(256, activation='relu')(roberta_input)\n",
    "    roberta_branch = layers.Dropout(0.3)(roberta_branch)\n",
    "    roberta_branch = layers.Dense(128, activation='relu')(roberta_branch)\n",
    "\n",
    "    # Concatenate and output\n",
    "    combined = Multiply()([bert_branch, roberta_branch])\n",
    "    combined = layers.Dropout(0.3)(combined)\n",
    "    output = layers.Dense(1, activation='sigmoid')(combined)\n",
    "\n",
    "    model = models.Model(inputs=[bert_input, roberta_input], outputs=output)\n",
    "    model.compile(optimizer=optimizers.Adam(1e-4),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_multiply(bert, roberta, y):\n",
    "    X_train_bert, X_val_bert, y_train, y_val = train_test_split(\n",
    "        bert, y, test_size=0.2, stratify=y, random_state=42)\n",
    "    X_train_roberta, X_val_roberta, _, _ = train_test_split(\n",
    "        roberta, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "    model_multiply = build_model()\n",
    "\n",
    "    early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    model_multiply.fit(\n",
    "        [X_train_bert, X_train_roberta], y_train,\n",
    "        validation_data=([X_val_bert, X_val_roberta], y_val),\n",
    "        epochs=100,\n",
    "        batch_size=64,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "\n",
    "    y_pred_prob = model_multiply.predict([X_val_bert, X_val_roberta])\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    print(f\"Accuracy : {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall   : {rec:.4f}\")\n",
    "    print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "    return model_multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6721 - loss: 0.6020 - val_accuracy: 0.7194 - val_loss: 0.5445\n",
      "Epoch 2/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7156 - loss: 0.5510 - val_accuracy: 0.7240 - val_loss: 0.5356\n",
      "Epoch 3/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7233 - loss: 0.5418 - val_accuracy: 0.7253 - val_loss: 0.5313\n",
      "Epoch 4/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7277 - loss: 0.5361 - val_accuracy: 0.7286 - val_loss: 0.5282\n",
      "Epoch 5/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7300 - loss: 0.5307 - val_accuracy: 0.7285 - val_loss: 0.5268\n",
      "Epoch 6/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7336 - loss: 0.5272 - val_accuracy: 0.7318 - val_loss: 0.5247\n",
      "Epoch 7/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7351 - loss: 0.5234 - val_accuracy: 0.7321 - val_loss: 0.5235\n",
      "Epoch 8/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7368 - loss: 0.5207 - val_accuracy: 0.7346 - val_loss: 0.5224\n",
      "Epoch 9/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7401 - loss: 0.5178 - val_accuracy: 0.7348 - val_loss: 0.5234\n",
      "Epoch 10/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7421 - loss: 0.5166 - val_accuracy: 0.7349 - val_loss: 0.5221\n",
      "Epoch 11/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7426 - loss: 0.5121 - val_accuracy: 0.7359 - val_loss: 0.5208\n",
      "Epoch 12/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7443 - loss: 0.5104 - val_accuracy: 0.7368 - val_loss: 0.5201\n",
      "Epoch 13/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7459 - loss: 0.5086 - val_accuracy: 0.7369 - val_loss: 0.5202\n",
      "Epoch 14/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7465 - loss: 0.5055 - val_accuracy: 0.7352 - val_loss: 0.5226\n",
      "Epoch 15/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7494 - loss: 0.5025 - val_accuracy: 0.7346 - val_loss: 0.5223\n",
      "Epoch 16/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7520 - loss: 0.5006 - val_accuracy: 0.7370 - val_loss: 0.5225\n",
      "Epoch 17/100\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7527 - loss: 0.4975 - val_accuracy: 0.7349 - val_loss: 0.5224\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step\n",
      "Accuracy : 0.7368\n",
      "Precision: 0.7261\n",
      "Recall   : 0.7602\n",
      "F1 Score : 0.7428\n"
     ]
    }
   ],
   "source": [
    "# 실행\n",
    "bert, roberta, y = load_data(\"emb_cls.json\")\n",
    "model= train_model_multiply(bert, roberta, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
